{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstração de Algoritmos de Machine Learning\n",
    "\n",
    "Este notebook demonstra o uso dos algoritmos de machine learning implementados neste repositório.\n",
    "Vamos usar os conjuntos de dados sintéticos gerados nos scripts da pasta `data` para testar os diversos algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações necessárias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os Dados\n",
    "\n",
    "Vamos importar os geradores de dados que criamos para poder testar os algoritmos com diferentes tipos de conjuntos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar geradores de dados\n",
    "from data.classificacao import gerar_classificacao_linear, gerar_classificacao_nao_linear, gerar_xor, gerar_multiclasse, visualizar\n",
    "from data.regressao import gerar_regressao_linear, gerar_regressao_polinomial, gerar_regressao_senoidal, gerar_regressao_multipla, visualizar_regressao\n",
    "from data.clustering import gerar_clusters, gerar_clusters_nao_lineares, gerar_dados_alta_dimensao, visualizar_clusters\n",
    "from data.reinforcement import AmbienteGrade, criar_ambiente_padrao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algoritmos de Aprendizado Supervisionado - Classificação\n",
    "\n",
    "### 1.1 K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar algoritmo KNN\n",
    "from supervised.knn.knn import KNN\n",
    "\n",
    "# Gerar dados para classificação linear\n",
    "X, y = gerar_classificacao_linear(n_amostras=200, n_atributos=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualizar dados\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "visualizar(X_train, y_train, \"Dados de Treinamento\")\n",
    "\n",
    "# Treinar e testar KNN\n",
    "knn = KNN(k=3)\n",
    "knn.treinar(X_train, y_train)\n",
    "y_pred = knn.prever(X_test)\n",
    "\n",
    "# Avaliar desempenho\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do KNN: {accuracy:.4f}\")\n",
    "\n",
    "# Visualizar predições\n",
    "plt.subplot(1, 2, 2)\n",
    "visualizar(X_test, y_pred, \"Predições do KNN\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Visualizar fronteira de decisão\n",
    "def visualizar_fronteira_decisao(X, y, modelo, titulo, ax=None):\n",
    "    # Definir limites para os eixos\n",
    "    h = 0.02  # Tamanho do passo na malha\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Prever rótulos para cada ponto na malha\n",
    "    Z = modelo.prever(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "    # Plotar a fronteira de decisão\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
    "    \n",
    "    # Plotar os pontos\n",
    "    cores = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    for i in np.unique(y):\n",
    "        ax.scatter(X[y == i, 0], X[y == i, 1], \n",
    "                  color=cores[int(i) % len(cores)], \n",
    "                  label=f'Classe {i}', \n",
    "                  edgecolors='k')\n",
    "    \n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_title(titulo)\n",
    "    ax.set_xlabel('Atributo 1')\n",
    "    ax.set_ylabel('Atributo 2')\n",
    "    ax.legend()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "visualizar_fronteira_decisao(X, y, knn, f\"Fronteira de Decisão do KNN (k={knn.k})\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar algoritmo Naive Bayes\n",
    "from supervised.naive_bayes.naive_bayes import NaiveBayes\n",
    "\n",
    "# Gerar dados para classificação multiclasse\n",
    "X, y = gerar_classificacao_linear(n_amostras=200, n_atributos=2, n_classes=3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualizar dados\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "visualizar(X_train, y_train, \"Dados de Treinamento\")\n",
    "\n",
    "# Treinar e testar Naive Bayes\n",
    "nb = NaiveBayes()\n",
    "nb.treinar(X_train, y_train)\n",
    "y_pred = nb.prever(X_test)\n",
    "\n",
    "# Avaliar desempenho\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do Naive Bayes: {accuracy:.4f}\")\n",
    "\n",
    "# Visualizar predições\n",
    "plt.subplot(1, 2, 2)\n",
    "visualizar(X_test, y_pred, \"Predições do Naive Bayes\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Visualizar fronteira de decisão\n",
    "plt.figure(figsize=(12, 10))\n",
    "visualizar_fronteira_decisao(X, y, nb, \"Fronteira de Decisão do Naive Bayes\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar algoritmo de Árvore de Decisão\n",
    "from supervised.decision_tree.decision_tree import DecisionTree\n",
    "\n",
    "# Gerar dados XOR (não linearmente separáveis)\n",
    "X, y = gerar_xor(n_amostras=200, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualizar dados\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "visualizar(X_train, y_train, \"Dados de Treinamento (XOR)\")\n",
    "\n",
    "# Treinar e testar Árvore de Decisão\n",
    "dt = DecisionTree(max_depth=5)\n",
    "dt.treinar(X_train, y_train)\n",
    "y_pred = dt.prever(X_test)\n",
    "\n",
    "# Avaliar desempenho\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia da Árvore de Decisão: {accuracy:.4f}\")\n",
    "\n",
    "# Visualizar predições\n",
    "plt.subplot(1, 2, 2)\n",
    "visualizar(X_test, y_pred, \"Predições da Árvore de Decisão\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Visualizar fronteira de decisão\n",
    "plt.figure(figsize=(12, 10))\n",
    "visualizar_fronteira_decisao(X, y, dt, f\"Fronteira de Decisão da Árvore (profundidade={dt.max_depth})\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar algoritmo SVM\n",
    "from supervised.svm.svm import SVM\n",
    "\n",
    "# Gerar dados para classificação não linear\n",
    "X, y = gerar_classificacao_nao_linear('moons', n_amostras=200, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualizar dados\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "visualizar(X_train, y_train, \"Dados de Treinamento (Moons)\")\n",
    "\n",
    "# Treinar e testar SVM\n",
    "svm = SVM(learning_rate=0.01, n_iters=1000, kernel='rbf')\n",
    "svm.treinar(X_train, y_train)\n",
    "y_pred = svm.prever(X_test)\n",
    "\n",
    "# Avaliar desempenho\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do SVM: {accuracy:.4f}\")\n",
    "\n",
    "# Visualizar predições\n",
    "plt.subplot(1, 2, 2)\n",
    "visualizar(X_test, y_pred, \"Predições do SVM\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Visualizar fronteira de decisão\n",
    "plt.figure(figsize=(12, 10))\n",
    "visualizar_fronteira_decisao(X, y, svm, f\"Fronteira de Decisão do SVM (kernel={svm.kernel})\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algoritmos de Aprendizado Supervisionado - Regressão\n",
    "\n",
    "### 2.1 Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar algoritmo de Regressão Linear\n",
    "from supervised.linear_regression.linear_regression import LinearRegression\n",
    "\n",
    "# Gerar dados para regressão linear\n",
    "X, y = gerar_regressao_linear(n_amostras=100, n_atributos=1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualizar dados\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X[:, 0], y, color='blue', alpha=0.7, label='Dados')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Dados de Regressão Linear')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Treinar e testar Regressão Linear\n",
    "lr = LinearRegression(learning_rate=0.01, n_iters=1000)\n",
    "lr.treinar(X_train, y_train)\n",
    "y_pred = lr.prever(X_test)\n",
    "\n",
    "# Avaliar desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE da Regressão Linear: {mse:.4f}\")\n",
    "print(f\"Coeficientes: {lr.coef_}\")\n",
    "print(f\"Intercepto: {lr.intercept_}\")\n",
    "\n",
    "# Visualizar a linha de regressão\n",
    "x_range = np.linspace(X[:, 0].min(), X[:, 0].max(), 100).reshape(-1, 1)\n",
    "y_pred_line = lr.prever(x_range)\n",
    "plt.plot(x_range, y_pred_line, color='red', linewidth=3, label='Linha de Regressão')\n",
    "plt.scatter(X_test[:, 0], y_test, color='green', marker='x', s=100, label='Teste')\n",
    "plt.scatter(X_test[:, 0], y_pred, color='orange', marker='o', s=100, label='Predições')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Algoritmos de Aprendizado Não Supervisionado\n",
    "\n",
    "### 3.1 K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar algoritmo K-Means\n",
    "from unsupervised.kmeans.kmeans import KMeans\n",
    "\n",
    "# Gerar dados para clustering\n",
    "X, y_true = gerar_clusters(n_amostras=300, n_clusters=4, random_state=42)\n",
    "\n",
    "# Visualizar dados originais\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "visualizar_clusters(X, y_true, \"Clusters Originais\")\n",
    "\n",
    "# Treinar K-Means e obter clusters\n",
    "kmeans = KMeans(K=4, max_iters=100, plot_steps=False)\n",
    "y_pred = kmeans.prever(X)\n",
    "\n",
    "# Visualizar clusters encontrados\n",
    "plt.subplot(1, 2, 2)\n",
    "visualizar_clusters(X, y_pred, \"Clusters Encontrados pelo K-Means\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Visualizar centroides\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = visualizar_clusters(X, y_pred, \"Clusters e Centroides do K-Means\")\n",
    "centroides = kmeans.centroides\n",
    "ax.scatter(centroides[:, 0], centroides[:, 1], \n",
    "           marker='*', s=300, c='black', label='Centroides')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar algoritmo PCA\n",
    "from unsupervised.pca.pca import PCA\n",
    "\n",
    "# Gerar dados de alta dimensão\n",
    "X, y = gerar_dados_alta_dimensao(n_amostras=200, n_atributos=10, n_informative=2, n_clusters=3, random_state=42)\n",
    "\n",
    "# Visualizar os dados originais (apenas as duas primeiras dimensões)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "visualizar_clusters(X[:, :2], y, \"Dados Originais (2 primeiras dimensões)\")\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA(n_componentes=2)\n",
    "X_reduzido = pca.transformar(X)\n",
    "\n",
    "# Visualizar dados após a redução de dimensionalidade\n",
    "plt.subplot(1, 2, 2)\n",
    "visualizar_clusters(X_reduzido, y, \"Dados após PCA (2 componentes)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Visualizar variância explicada\n",
    "plt.figure(figsize=(10, 6))\n",
    "variancia_explicada = pca.variancia_explicada\n",
    "plt.bar(range(len(variancia_explicada)), variancia_explicada, alpha=0.7)\n",
    "plt.plot(range(len(variancia_explicada)), np.cumsum(variancia_explicada), marker='o', linestyle='-', color='red')\n",
    "plt.xlabel('Componente Principal')\n",
    "plt.ylabel('Proporção de Variância Explicada')\n",
    "plt.title('Variância Explicada por Componente')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aprendizado por Reforço\n",
    "\n",
    "### 4.1 Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar algoritmo Q-Learning\n",
    "from reinforcement.qlearning.qlearning import QLearning\n",
    "\n",
    "# Criar ambiente de grade\n",
    "ambiente = criar_ambiente_padrao()\n",
    "\n",
    "# Visualizar ambiente inicial\n",
    "plt.figure(figsize=(10, 10))\n",
    "ambiente.renderizar()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Treinar agente Q-Learning\n",
    "qlearner = QLearning(\n",
    "    num_estados=ambiente.obter_espaco_estados(),\n",
    "    num_acoes=ambiente.obter_espaco_acoes(),\n",
    "    taxa_aprendizado=0.1,\n",
    "    fator_desconto=0.99,\n",
    "    epsilon=0.1\n",
    ")\n",
    "\n",
    "# Função auxiliar para converter posição (x, y) para índice de estado\n",
    "def posicao_para_estado(posicao, largura):\n",
    "    x, y = posicao\n",
    "    return y * largura + x\n",
    "\n",
    "# Função auxiliar para converter índice de estado para posição (x, y)\n",
    "def estado_para_posicao(estado, largura):\n",
    "    x = estado % largura\n",
    "    y = estado // largura\n",
    "    return (x, y)\n",
    "\n",
    "# Treinar o agente\n",
    "num_episodios = 500\n",
    "max_passos = 100\n",
    "recompensas_por_episodio = []\n",
    "\n",
    "for episodio in range(num_episodios):\n",
    "    # Reiniciar ambiente\n",
    "    posicao_atual = ambiente.reset()\n",
    "    estado_atual = posicao_para_estado(posicao_atual, ambiente.largura)\n",
    "    terminado = False\n",
    "    recompensa_total = 0\n",
    "    passos = 0\n",
    "    \n",
    "    while not terminado and passos < max_passos:\n",
    "        # Escolher ação usando política epsilon-greedy\n",
    "        acao = qlearner.selecionar_acao(estado_atual)\n",
    "        \n",
    "        # Executar ação no ambiente\n",
    "        nova_posicao, recompensa, terminado = ambiente.passo(acao)\n",
    "        novo_estado = posicao_para_estado(nova_posicao, ambiente.largura)\n",
    "        \n",
    "        # Atualizar Q-table\n",
    "        qlearner.atualizar(estado_atual, acao, recompensa, novo_estado, terminado)\n",
    "        \n",
    "        # Atualizar estado atual\n",
    "        estado_atual = novo_estado\n",
    "        recompensa_total += recompensa\n",
    "        passos += 1\n",
    "    \n",
    "    recompensas_por_episodio.append(recompensa_total)\n",
    "    \n",
    "    # Imprimir progresso a cada 100 episódios\n",
    "    if (episodio + 1) % 100 == 0:\n",
    "        print(f\"Episódio {episodio + 1}/{num_episodios}, Recompensa: {recompensa_total:.2f}, Passos: {passos}\")\n",
    "\n",
    "# Visualizar curva de aprendizado\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(recompensas_por_episodio, label='Recompensa por Episódio')\n",
    "plt.xlabel('Episódio')\n",
    "plt.ylabel('Recompensa Total')\n",
    "plt.title('Curva de Aprendizado do Q-Learning')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Extrair a política aprendida\n",
    "politica = np.zeros((ambiente.altura, ambiente.largura), dtype=int)\n",
    "for y in range(ambiente.altura):\n",
    "    for x in range(ambiente.largura):\n",
    "        estado = posicao_para_estado((x, y), ambiente.largura)\n",
    "        politica[y, x] = np.argmax(qlearner.Q[estado, :])\n",
    "\n",
    "# Visualizar a política aprendida\n",
    "plt.figure(figsize=(10, 10))\n",
    "ambiente.renderizar(politica=politica)\n",
    "plt.title('Política Aprendida pelo Q-Learning')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deep Learning\n",
    "\n",
    "### 5.1 Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar algoritmo de Rede Neural\n",
    "from deep_learning.neural_network.neural_network import NeuralNetwork, Layer\n",
    "\n",
    "# Função para normalizar os dados\n",
    "def normalizar(X):\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Gerar dados para classificação não linear\n",
    "X, y = gerar_classificacao_nao_linear('moons', n_amostras=300, random_state=42)\n",
    "X = normalizar(X)  # Normalizar para melhor convergência da rede neural\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualizar dados\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "visualizar(X_train, y_train, \"Dados de Treinamento (Moons)\")\n",
    "\n",
    "# Converter rótulos para one-hot encoding para classificação com rede neural\n",
    "def to_categorical(y, num_classes=None):\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    return categorical\n",
    "\n",
    "# Converter de one-hot encoding para rótulos\n",
    "def from_categorical(y_cat):\n",
    "    return np.argmax(y_cat, axis=1)\n",
    "\n",
    "# Converter rótulos para formato adequado\n",
    "y_train_cat = to_categorical(y_train, num_classes=2)\n",
    "num_classes = y_train_cat.shape[1]\n",
    "\n",
    "# Criar e treinar rede neural\n",
    "nn = NeuralNetwork()\n",
    "nn.add(Layer(2, 16, activation='relu'))  # Camada de entrada: 2 neurônios (atributos), 16 neurônios na camada oculta\n",
    "nn.add(Layer(16, 8, activation='relu'))  # Segunda camada oculta\n",
    "nn.add(Layer(8, num_classes, activation='softmax'))  # Camada de saída: num_classes neurônios\n",
    "\n",
    "# Treinar a rede\n",
    "historia = nn.treinar(X_train, y_train_cat, learning_rate=0.1, n_epochs=1000, batch_size=32)\n",
    "\n",
    "# Fazer predições\n",
    "y_pred_cat = nn.prever(X_test)\n",
    "y_pred = from_categorical(y_pred_cat)\n",
    "\n",
    "# Avaliar desempenho\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia da Rede Neural: {accuracy:.4f}\")\n",
    "\n",
    "# Visualizar predições\n",
    "plt.subplot(1, 2, 2)\n",
    "visualizar(X_test, y_pred, \"Predições da Rede Neural\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Visualizar fronteira de decisão\n",
    "class NeuralNetworkWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def prever(self, X):\n",
    "        y_pred = self.model.prever(X)\n",
    "        return from_categorical(y_pred)\n",
    "\n",
    "nn_wrapper = NeuralNetworkWrapper(nn)\n",
    "plt.figure(figsize=(12, 10))\n",
    "visualizar_fronteira_decisao(X, y, nn_wrapper, \"Fronteira de Decisão da Rede Neural\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Visualizar histórico de perda (loss)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(historia['loss'], label='Perda (Loss)')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Perda')\n",
    "plt.title('Histórico de Treinamento da Rede Neural')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Neste notebook, demonstramos o uso de diversos algoritmos de machine learning implementados do zero:\n",
    "\n",
    "1. **Algoritmos de Classificação Supervisionada**:\n",
    "   - K-Nearest Neighbors (KNN)\n",
    "   - Naive Bayes\n",
    "   - Árvore de Decisão\n",
    "   - Support Vector Machine (SVM)\n",
    "\n",
    "2. **Algoritmos de Regressão Supervisionada**:\n",
    "   - Regressão Linear\n",
    "\n",
    "3. **Algoritmos de Aprendizado Não Supervisionado**:\n",
    "   - K-Means\n",
    "   - PCA (Principal Component Analysis)\n",
    "\n",
    "4. **Algoritmos de Aprendizado por Reforço**:\n",
    "   - Q-Learning\n",
    "\n",
    "5. **Deep Learning**:\n",
    "   - Rede Neural Feed-Forward\n",
    "\n",
    "Cada algoritmo foi testado com conjuntos de dados adequados para demonstrar suas capacidades e limitações.\n",
    "Esta implementação serve principalmente para fins educacionais, permitindo compreender os fundamentos desses algoritmos.\n",
    "Para aplicações em produção, recomenda-se o uso de bibliotecas como scikit-learn, TensorFlow ou PyTorch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
